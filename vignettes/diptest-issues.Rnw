\documentclass{article}
%
\usepackage{myVignette}
\usepackage{fullpage}% save trees ;-) --- FIXME use {geometry} package
\usepackage[authoryear,round,longnamesfirst]{natbib}
\bibliographystyle{plainnat}
%
%%\VignetteIndexEntry{Dip Test Explorations}
%%\VignetteDepends{diptest}
\SweaveOpts{engine=R,keep.source=TRUE,strip.white=true}
%		     ^^^^^^^^^^^^^^^^
\SweaveOpts{eps=FALSE,pdf=TRUE,width=7,height=4}
\title{Dip Test Explorations}
\author{Martin Maechler\\ Seminar f\"ur Statistik \\ ETH Zurich, \ Switzerland
  \\\email{maechler@stat.math.ethz.ch}}
\date{April 2009 ({\tiny typeset on \tiny\today})}
%
\begin{document}
\maketitle
\begin{abstract}
\end{abstract}

%% Note: These are explained in '?RweaveLatex' :
<<preliminaries, echo=FALSE>>=
require("diptest")
options(width=75)
set.seed(47)
@

\section{Introduction}
\label{sec:Intro}

%% MM
FIXME: Need notation

$D_n :=$\texttt{dip( runif(n) )};

but more generally,
\begin{equation}
  \label{eq:Dn.F}
  D_n(F) := D(X_1, X_2, \dots, X_n),  \mbox{ \ \ \texttt{where} } X_i \iid, X_i \sim F.
\end{equation}

\citet{HarJH85} in their ``seminal'' paper on the dip statistic $D_n$
already proved that $ \sqrt{n} \; D_n$ converges in distribution, i.e.,
$ \lim_{n\to\infty}\sqrt{n} \; D_n \isD  D_\infty$.

A considerable part of this paper is devoted to explore the distribution of $D_\infty$.

\bigskip
\section{History of the \texttt{diptest} \RR\ package}

\citet{HarP85} published an implementation in Fortran of a concrete algorithm,
% ALGORITHM AS 217 APPL. STATIST. (1985) VOL.34, NO.3
where the code was also made available on Statlib\footnote{Statlib is now a
  website, of course, \url{http://lib.stat.cmu.edu/}, but then was \emph{the} preferred way
  for distributing algorithm for statistical computing, available years
  before the existence of the WWW, and entailing e-mail and (anonymous) FTP}

- MM started in 1994, with S-plus code interfacing to Hartigan's Fortran

- several important bug fixes;
  last one Oct./Nov.~2003

  However, the Fortran code file \url{http://lib.stat.cmu.edu/apstat/217},
  was last changed {Thu 04 Aug 2005 03:43:28 PM CEST}

  We have some results of the dip.dist of \emph{before} the bug fix;
  notably the ``dip of the dip'' probabilities have changed considerably!!

- see rcslog of ../../src/dip.c

\section{21st Century Improvement of  Hartigan$^2$'s Table}

((

Use listing package (or so to more or less ``cut \& paste'' the nice code in
\texttt{../../stuff/new-simul.Rout-1e6}

))

\section{The Dip in the Dip's Distribution}
\label{sec:dip_dip}
We have found empirically that the dip distribution itself starts with a dip.
Specifically, the minimal possible value of $D_n$ is $\frac{1}{2n}$
\emph{and} the probability of reaching that value,
\begin{equation}
  \label{eq:P.Dn_min}
  \PR{D_n = \frac{1}{2n}},
\end{equation}
is large for small $n$.

E.g., consider an approximation of the dip distribution for $n=5$,
<<dip_n-is-5,fig=TRUE>>=
D5 <- replicate(10000, dip(runif(5)))
hist(D5, breaks=128, main = "Histogram of  replicate(10'000, dip(runif(5))))")
@

which looks as if there was a bug in the software --- but that look is misleading!
Note how the phenomenon is still visible for $n=8$,
<<dip_n-is-8,fig=TRUE>>=
D8 <- replicate(10000, dip(runif(8)))
hist(D8, breaks=128, main = "Histogram of  replicate(10'000, dip(runif(8))))")
@

%% NOTE that there's another phenomenon I haven't seen before;
%% particularly, if we use 100'000 replicates ....
%--------------------
% set.seed(11)
% D11 <- replicate(100000, dip(runif(11)))
% save(D11, file="/u/maechler/R/Pkgs/diptest/stuff/D11.rda")
% hist(D11, breaks=128, main = "Histogram of  replicate(100'000, dip(runif(11)))")
%--------------------
FIXME:\\
use ../../stuff/sim-minProb.R
and ../../stuff/minProb-anal.R

Further, it can be seen that the \emph{maximal} dip statistic
is $\frac 1 4 = 0.25$ (for even $n$) and this upper bound can be reached
simply using the the data $(0,0\,dots,0, \; 1, 1,\dots,1)$, a bi-point mass
with the mass at each point.

\section{P-values for the Dip Test}
\label{sec:Pvals}

\subsection{Interpolating the Dip Table}
\label{sec:interpol}
Because of the asymptotic distribution,
$ \lim_{n\to\infty}\sqrt{n} \; D_n \isD  D_\infty$,
it is makes sense to consider the ``$\sqrt{n} D_n$''--scale,
even for finite $n$ values:
<<sqrt-n-qdip,fig=true>>=
dnqd <- dimnames(qDiptab)
(nn. <- as.integer(dnqd[["n"]]))
matplot(nn., qDiptab*sqrt(nn.), type ="o", pch=1, cex = 0.4,
        log="x", xlab="n   [log scaled]",
        ylab = expression(sqrt(n) %*% q[D[n]]))
## Note that  1/2n  is the first possible value (with finite mass),,
## clearly visible for (very) small n:
lines(nn., sqrt(nn.)/(2*nn.), col=adjustcolor("yellow2",0.5), lwd=3)

P.p <- as.numeric(print(noquote(dnqd[["Pr"]])))
## Now look at one well known data set:
D <- dip(x <- faithful$waiting)
n <- length(x)
points(n, sqrt(n)*D, pch=13, cex=2, col= adjustcolor("blue2",.5), lwd=2)
## a simulated (approximate) P-value for D  is
mean(D <= replicate(10000, dip(runif(n)))) ## ~ 0.002
@
but we can use our table to compute a deterministic (but still approximate,
as the table is from simulation too) P-value:
%%% ------------------------------- =====
%%% ------------------------------- FIXME  -- make this into a documented function!
%%% ------------------------------- =====
<<interpolate-dip-table>>=
## We are in this interval:
n0 <- nn.[i.n <- findInterval(n, nn.)]
n1 <- nn.[i.n +1] ; c(n0, n1)
f.n <- (n - n0)/(n1 - n0)# in [0, 1]
## Now "find" y-interval:
y.0 <- sqrt(n0)* qDiptab[i.n  ,]
y.1 <- sqrt(n1)* qDiptab[i.n+1,]
(Pval <- 1 - approx(y.0 + f.n*(y.1 - y.0),
                    P.p,
                    xout = sqrt(n) * D)[["y"]])
## 0.018095
@

\subsection{Asymptotic Dip Distribution}
\label{sec:asymp}

%% Maybe
\section{Less Conservative Dip Testing}


\section{Session Info}

<<sessionInfo, results=tex>>=
toLatex(sessionInfo())
@

\bibliography{diptest}

\end{document}
